# ðŸ· Wine Quality Prediction (Regression)

This project predicts the quality of red wine based on physicochemical features using Machine Learning. It demonstrates a complete ML pipeline: **data loading, exploratory data analysis (EDA), model training, evaluation, and saving the best model**.

---

## ðŸ“‚ Project Structure

ml-projects/02_wine_quality/
â”‚
â”œâ”€â”€ data_loader.py # Load the dataset
â”œâ”€â”€ visualize.py # Exploratory Data Analysis using Seaborn/Matplotlib
â”œâ”€â”€ model_trainer.py # Train Linear Regression, Random Forest, Gradient Boosting models
â”œâ”€â”€ evaluator.py # Evaluate models using RÂ² Score and RMSE
â”œâ”€â”€ model_exporter.py # Save the best model as wine_quality_model.pkl
â”œâ”€â”€ main.py # Integrates all scripts into a single pipeline
â”œâ”€â”€ winequality-red.csv # Dataset (Kaggle Red Wine dataset)
â”œâ”€â”€ wine_quality_model.pkl # Saved best model
â””â”€â”€ README.md


---

## ðŸ“ Dataset

- Source: [Kaggle Wine Quality Dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)  
- Type: Regression  
- Features (12 numeric physicochemical attributes):
  - fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, alcohol
- Target:
  - `quality` (score between 0â€“10)

---

## ðŸ” Exploratory Data Analysis (EDA)

- Checked for missing values â†’ **No missing values** âœ…  
- Visualizations:
  - Pairplot for feature relationships  
  - Correlation heatmap to find important features  

---

## ðŸ¤– Models Trained

1. **Linear Regression**  
2. **Random Forest Regressor**  
3. **Gradient Boosting Regressor**

**Evaluation Metrics:**
- **RÂ² Score**: Measures how much variance is explained by the model (higher = better)  
- **RMSE (Root Mean Squared Error)**: Measures average prediction error (lower = better)

**Results:**

| Model                  | RÂ² Score | RMSE  |
|------------------------|----------|-------|
| Linear Regression      | 0.31     | 0.618 |
| Random Forest          | 0.46     | 0.546 |
| Gradient Boosting      | 0.40     | 0.575 |

> Random Forest is the best model for this dataset.

---

## ðŸ’¾ Saving the Model

- The best-performing model (`Random Forest`) is saved as `wine_quality_model.pkl` using `joblib`.  
- This allows **loading and using the model later** without retraining.

---

## âš¡ How to Run

1. Clone the repository:
```bash
git clone <your-repo-url>
cd ml-projects/02_wine_quality/

Install dependencies:
pip install -r requirements.txt

Run the pipeline:
python main.py

This will execute the full ML pipeline: load data â†’ visualize â†’ train â†’ evaluate â†’ save best model.

ðŸ›  Tools & Libraries

Python 3.x

pandas, numpy

scikit-learn

matplotlib, seaborn

joblib


ðŸ“ˆ Next Steps / Improvements

Hyperparameter tuning for Random Forest & Gradient Boosting

Cross-validation for more robust evaluation

Feature importance analysis

Try additional regression models (XGBoost, LightGBM)


ðŸ“Œ Author

Shankar Kumar

GitHub: https://github.com/Shank312


